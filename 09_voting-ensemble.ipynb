{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보팅 앙상블\n",
    "단일 모델을 앙상블하여 더 나은 예측을 하는 앙상블 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# sklearn 모델의 동일한 결과 출력을 위해 선언합니다.\n",
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits()\n",
    "features, labels = mnist.data, mnist.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(features,labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단일 모델 정확도 측정\n",
    "의사결정트리, knn, svm 모델의 정확도를 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(\n",
    "    criterion=\"gini\", max_depth=8, max_features=32,random_state=35)\n",
    "\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "dtree_predicted = dtree.predict(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=299).fit(X_train, y_train)\n",
    "knn_predicted = knn.predict(X_test)\n",
    "\n",
    "svm = SVC(C=0.1, gamma=0.003,\n",
    "          probability=True,random_state=35).fit(X_train, y_train)\n",
    "svm_predicted = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[accuarcy]\")\n",
    "print(\"d-tree: \",accuracy_score(y_test, dtree_predicted))\n",
    "print(\"knn   : \",accuracy_score(y_test, knn_predicted))\n",
    "print(\"svm   : \",accuracy_score(y_test, svm_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소프트 보팅 또는 하드 보팅은 sklearn의 voting classifier를 사용하여 쉽게 구현할 수 있습니다.  \n",
    "직접 소프트 보팅을 구현하실 때는 predict_proba 함수를 사용하여 테스트 수행 시 측정된 분류값 별 확률을 사용하시면 됩니다.  \n",
    "아래 SVM으로부터 나온 테스트 데이터 2개의 0부터 9까지의 확률을 보실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_proba = svm.predict_proba(X_test)\n",
    "print(svm_proba[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하드 보팅\n",
    "하드 보팅은 일반적인 투표와 같이, 각각의 분류기의 예측값들을 모아, 가장 많은 득표를 받은 예측값으로 최종 결론을 내는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('decision_tree', dtree), ('knn', knn), ('svm', svm)], \n",
    "    weights=[1,1,1], voting='hard').fit(X_train, y_train)\n",
    "hard_voting_predicted = voting_clf.predict(X_test)\n",
    "accuracy_score(y_test, hard_voting_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소프트 보팅\n",
    "소프트 보팅은 각각의 분류모델의 predict_proba을 활용하여, 모든 분류값들의 확률들을 더해서,  \n",
    "가장 높은 점수를 획득한 분류값으로 최종 결론을 내는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('decision_tree', dtree), ('knn', knn), ('svm', svm)], \n",
    "    weights=[1,1,1], voting='soft').fit(X_train, y_train)\n",
    "soft_voting_predicted = voting_clf.predict(X_test)\n",
    "accuracy_score(y_test, soft_voting_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도 비교 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(5)\n",
    "plt.bar(x, height= [accuracy_score(y_test, dtree_predicted),\n",
    "                    accuracy_score(y_test, knn_predicted),\n",
    "                    accuracy_score(y_test, svm_predicted),\n",
    "                    accuracy_score(y_test, hard_voting_predicted),\n",
    "                    accuracy_score(y_test, soft_voting_predicted)])\n",
    "plt.xticks(x, ['decision tree','knn','svm','hard voting','soft voting']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
